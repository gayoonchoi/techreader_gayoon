{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(result_type=\"markdown\", language=\"ko\")\n",
    "\n",
    "file_path = r\"techreader_data\\LLM_TechLibrary.pdf\"\n",
    "parsed_docs = parser.load_data(file_path=file_path)  # 이제 정상 실행됨\n",
    "\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "print(docs[0].page_content[:500])  # 일부 미리보기\n",
    "\n",
    "import os\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "# PDF 파서 초기화\n",
    "parser = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"gemini-2.5-pro\",\n",
    "    vendor_multimodal_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    parsing_mode=\"Unstructured\",\n",
    "    language=\"ko\",\n",
    "    parsing_instruction=\"\"\"\n",
    "     당신은 PDF 문서를 구조화된 Markdown으로 변환하는 파서입니다.\n",
    "     \n",
    "    가장 중요한 규칙:\n",
    "    모든 텍스트는 가능한 모두 출력해주세요. \n",
    "    첫 페이지를 제외한 Tech Guide와 Tech Trend는 소제목이 아닙니다. \n",
    "    \n",
    "    \n",
    "    변환 규칙:\n",
    "    0. 원문 텍스트는 가능한 한 모두 보존하세요. \n",
    "    1. 문서의 '주요 제목'은 반드시 `# 제목` 형식으로 추출하세요.\n",
    "       - 제목 바로 아래 줄에 '저자 | 소속'이 있으면 `Author: 이름 | 소속`으로 출력하세요.\n",
    "    2. 본문 내의 소제목은 `## 소제목`으로 변환하세요. \n",
    "       - 단, '# 1.' 같은 번호 형식, 첫 페이지를 제외한 영어 한 단어, 결론을 제외한 짧은 음절(예: 비추천 용도, 최적 용도, 주의점)은 소제목으로 간주하지 마세요.\n",
    "    3. 제목/소제목 외의 일반 문단은 그냥 텍스트로 출력하세요. 특정 페이지에 일반 문단만 있어도 그대로 출력하세요. # 표시하지 마세요. \n",
    "    4. 일반 문단은 그냥 텍스트로 출력하되 • 표시로 시작하는 것도 그대로 출력해주세요.   \n",
    "    5. 모든 출력은 순수한 Markdown 형식으로 작성하세요. 불필요한 설명, 번역, 해설은 절대 추가하지 마세요. 텍스트를 요약하지 말고 그대로 출력하세요. \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 파일 경로\n",
    "file_path = r\"techreader_data\\LLM_TechLibrary.pdf\"\n",
    "# TechReader_gayoon\\techreader_data\\LLM_TechLibrary.pdf\n",
    "# PDF → 파싱\n",
    "parsed_docs = parser.load_data(file_path=file_path)\n",
    "\n",
    "# LangChain Document 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "\n",
    "# Markdown 저장\n",
    "file_root, _ = os.path.splitext(file_path)\n",
    "output_file_path = file_root + \"_parsed0903_gemini.md\"\n",
    "\n",
    "full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(full_text)\n",
    "\n",
    "print(f\"✅ 파일 저장 완료: {output_file_path}\")\n",
    "\n",
    "\n",
    "import os\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "# 1. 마크다운 파일 불러오기\n",
    "with open(\"techreader_data/LLM_TechLibrary_parsed0903_gemini.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    markdown_text = f.read()\n",
    "\n",
    "# 2. 분할 기준 헤더 정의\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),    # # 제목\n",
    "    (\"##\", \"Header 2\"),   # ## 소제목\n",
    "    (\"###\", \"Header 3\"),  # ### 하위 소제목\n",
    "]\n",
    "\n",
    "# 3. Splitter 초기화\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# 4. 문서 분할\n",
    "md_header_splits = markdown_splitter.split_text(markdown_text)\n",
    "\n",
    "# 5. 결과 출력\n",
    "for i, doc in enumerate(md_header_splits[:10]):  # 앞에서 10개만 출력\n",
    "    print(f\"==== Chunk {i+1} ====\")\n",
    "    print(doc.page_content[:300])  # 앞부분 미리보기\n",
    "    print(\"메타데이터:\", doc.metadata)\n",
    "    print()\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(\"techreader_data/chunks_output.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Chunk No\", \"Metadata\", \"Content\"])\n",
    "    for i, doc in enumerate(md_header_splits, start=1):\n",
    "        writer.writerow([i, doc.metadata, doc.page_content.strip()])\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "# 1. OpenAI Embedding 초기화\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# 2. md_header_splits (문서 리스트)를 벡터화 후 저장\n",
    "vectorstore = FAISS.from_documents(md_header_splits, embeddings)\n",
    "\n",
    "# 3. 저장\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "\n",
    "print(\"✅ 벡터스토어 저장 완료: faiss_index 폴더 생성됨\")\n",
    "\n",
    "\n",
    "# 저장된 FAISS 인덱스 불러오기\n",
    "new_vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# 검색 \n",
    "query = \"교사 모델과 학생 모델의 관계에서 발생하는 보안 위험은 무엇인가요?\"\n",
    "docs = new_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "for d in docs:\n",
    "    print(\"📌\", d.page_content[:300])\n",
    "    print(\"메타데이터:\", d.metadata)\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Google AI Studio에서 발급받은 API 키 설정\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Gemini 모델 초기화 (최신은 gemini-1.5-pro 또는 gemini-1.5-flash)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "def generate_questions(header1, header2=None):\n",
    "    topic = header1 if header2 is None else f\"{header1} - {header2}\"\n",
    "    prompt = f\"\"\"\n",
    "    너는 AI 최신 기술 동향을 분석해 사내 엔지니어와 연구원이 빠르게 이해할 수 있도록\n",
    "    핵심 쟁점을 질문 형태로 정리하는 역할이다.\n",
    "    지금 다루는 문서는 Tech Library Top1에 선정된 21페이지짜리 리포트이며, 재직자 전용이다.\n",
    "    너의 목표는 주제와 관련된 기술적 쟁점과 연구 방향을 드러내는 예상 질문을 생성하는 것이다.\n",
    "\n",
    "    [요구사항]\n",
    "    - 주제: {topic}\n",
    "    - 예상 질문은 총 5개를 만들어라.\n",
    "    - 질문은 학생용 단순 이해 차원이 아니라, 엔지니어/연구자가\n",
    "      토론·실험·설계 단계에서 실제로 고민할 만한 '기술적 질문'이어야 한다.\n",
    "    - 질문은 명확하고 구체적으로 작성하라.\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip().split(\"\\n\")\n",
    "\n",
    "\n",
    "questions_dict = {}\n",
    "\n",
    "for doc in md_header_splits:\n",
    "    h1 = doc.metadata.get(\"Header 1\")\n",
    "    h2 = doc.metadata.get(\"Header 2\")\n",
    "\n",
    "    if (h1, h2) not in questions_dict:\n",
    "        q_list = generate_questions(h1, h2)\n",
    "        questions_dict[(h1, h2)] = q_list\n",
    "\n",
    "# 확인\n",
    "for (h1, h2), q_list in questions_dict.items():\n",
    "    print(f\"\\n📌 {h1} > {h2 if h2 else ''}\")\n",
    "    for q in q_list:\n",
    "        print(\" -\", q)\n",
    "\n",
    "\n",
    "# 보고서 본문 기반 질문 리스트\n",
    "content_questions_dict = {}\n",
    "\n",
    "for doc in md_header_splits:\n",
    "    h1 = doc.metadata.get(\"Header 1\")\n",
    "    h2 = doc.metadata.get(\"Header 2\")\n",
    "    content = doc.page_content\n",
    "\n",
    "    if (h1, h2) not in content_questions_dict:\n",
    "        q_list = generate_questions_from_content(h1, h2, content)\n",
    "        content_questions_dict[(h1, h2)] = q_list\n",
    "\n",
    "# 확인\n",
    "for (h1, h2), q_list in content_questions_dict.items():\n",
    "    print(f\"\\n📌 {h1} > {h2 if h2 else ''}\")\n",
    "    for q in q_list:\n",
    "        print(\" -\", q)\n",
    "\n",
    "\n",
    "# 답변도 같이 생성하기 \n",
    "import csv\n",
    "\n",
    "def load_questions(csv_path):\n",
    "    questions = []\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            questions.append({\n",
    "                \"Header 1\": row[\"Header 1\"],\n",
    "                \"Header 2\": row[\"Header 2\"],\n",
    "                \"Question\": row[\"Question\"]\n",
    "            })\n",
    "    return questions\n",
    "\n",
    "questions = load_questions(\"techreader_data/content_based_questions_clean.csv\")\n",
    "print(f\"총 {len(questions)}개 질문 불러옴\")\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os, re\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "def clean_answer_text(text: str) -> str:\n",
    "    # 불필요한 멘트 제거\n",
    "    text = re.sub(r\"(네, 알겠습니다.*|물론입니다.*|다음은.*|아래와 같이.*)\", \"\", text)\n",
    "    text = re.sub(r\"[*#]{2,}\", \"\", text)  # ###, *** 제거\n",
    "    # 문장 끝의 ... → .\n",
    "    text = re.sub(r\"\\.{2,}\", \".\", text.strip())\n",
    "    return text.strip()\n",
    "\n",
    "def generate_answer(question, header1, header2, content):\n",
    "    prompt = f\"\"\"\n",
    "    너는 AI 최신 기술 리포트를 분석하는 LLM 엔지니어다.\n",
    "    문서 주제: {header1} - {header2 if header2 else \"\"}\n",
    "    본문 내용 (발췌): {content[:3000] if content else \"\"}\n",
    "\n",
    "    [요구사항]\n",
    "    - 아래 질문에 대해 보고서 본문을 근거로 심층적인 답변을 작성하라.\n",
    "    - 답변은 연구 보고서 스타일로 작성하며, 3~4문단으로 구성하라.\n",
    "    - 전체 분량은 800~1000자 내외가 되도록 하라.\n",
    "    - 각 문단은 완결된 문장으로 끝내라.\n",
    "    - 서론(질문의 중요성), 본론(기술적 근거·세부 분석), 결론(핵심 요약과 시사점) 구조를 따르라.\n",
    "    - 마지막 문장은 반드시 마침표 하나(.)로 끝내라. 불필요한 ... 은 쓰지 말라.\n",
    "    - 출력은 반드시 '답변: ' 형식으로 하라.\n",
    "    - 최종 답변은 반드시 마침표 하나(.)로 끝내라.\n",
    "    - '...' 나 불필요한 반복 마침표는 절대 사용하지 말라.\n",
    "\n",
    "\n",
    "    질문: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\"max_output_tokens\": 9096, \"temperature\": 0.7}\n",
    "        )\n",
    "\n",
    "        if response.candidates and response.candidates[0].content.parts:\n",
    "            answer = response.candidates[0].content.parts[0].text.strip()\n",
    "        else:\n",
    "            answer = \"[⚠️ 답변 없음: 토큰 한도 초과 또는 안전 필터 차단]\"\n",
    "\n",
    "    except Exception as e:\n",
    "        answer = f\"[⚠️ 에러 발생: {str(e)}]\"\n",
    "\n",
    "    # 후처리: 결론 보강\n",
    "    if not answer.endswith((\"이다.\", \"있다.\", \"할 수 있다.\")):\n",
    "        try:\n",
    "            fix_prompt = f\"\"\"\n",
    "            다음 답변이 결론 없이 끝났습니다. \n",
    "            불필요한 멘트(예: '네, 알겠습니다', '물론입니다', '다음은', '### 결론', '***')는 쓰지 말고, \n",
    "            보고서 스타일의 결론 문단(3~4문장)을 작성하세요. 마지막 문장은 반드시 마침표 하나(.)로 끝내라.\n",
    "\n",
    "            불완전 답변: {answer}\n",
    "            \"\"\"\n",
    "            fix_response = model.generate_content(fix_prompt)\n",
    "            if fix_response.candidates and fix_response.candidates[0].content.parts:\n",
    "                answer += \"\\n\\n\" + fix_response.candidates[0].content.parts[0].text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 마지막 정리 (멘트/###/*** 제거, ... → .)\n",
    "    return clean_answer_text(answer) or \"\"\n",
    "\n",
    "for i, q in enumerate(questions):  # 전체 다 돌림\n",
    "    h1, h2, question = q[\"Header 1\"], q[\"Header 2\"], q[\"Question\"]\n",
    "\n",
    "    # md_header_splits에서 헤더 매칭해서 본문 불러오기\n",
    "    content = \"\"\n",
    "    for doc in md_header_splits:\n",
    "        if doc.metadata.get(\"Header 1\") == h1 and doc.metadata.get(\"Header 2\") == h2:\n",
    "            content = doc.page_content\n",
    "            break\n",
    "\n",
    "    answer = generate_answer(question, h1, h2, content)\n",
    "    q[\"Answer\"] = answer  # 답변 추가\n",
    "\n",
    "    print(f\"\\nQ{i+1}/{len(questions)}: {question}\")\n",
    "    print(f\"A: {answer[:]}...\")  # 앞부분만 미리보기 \n",
    "    \n",
    "    \n",
    "    \n",
    "import csv\n",
    "\n",
    "output_path = \"techreader_data/content_based_questions_with_answers.csv\"\n",
    "\n",
    "with open(output_path, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    fieldnames = [\"Header 1\", \"Header 2\", \"Question\", \"Answer\"]\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for q in questions:\n",
    "        writer.writerow({\n",
    "            \"Header 1\": q[\"Header 1\"],\n",
    "            \"Header 2\": q[\"Header 2\"],\n",
    "            \"Question\": q[\"Question\"],\n",
    "            \"Answer\": q.get(\"Answer\", \"\")\n",
    "        })\n",
    "\n",
    "print(f\"✅ 최종 저장 완료: {output_path}\")\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "def load_questions(csv_path):\n",
    "    questions = []\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            questions.append({\n",
    "                \"Header 1\": row[\"Header 1\"],\n",
    "                \"Header 2\": row[\"Header 2\"],\n",
    "                \"Question\": row[\"Question\"]\n",
    "            })\n",
    "    return questions\n",
    "\n",
    "questions = load_questions(\"techreader_data/header_based_questions_clean.csv\")\n",
    "print(f\"총 {len(questions)}개 질문 불러옴\")\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os, re\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "def clean_answer_text(text: str) -> str:\n",
    "    # 불필요한 멘트 제거\n",
    "    text = re.sub(r\"(네, 알겠습니다.*|물론입니다.*|다음은.*|아래와 같이.*)\", \"\", text)\n",
    "    text = re.sub(r\"[*#]{2,}\", \"\", text)  # ###, *** 제거\n",
    "    # 문장 끝의 ... → .\n",
    "    text = re.sub(r\"\\.{2,}\", \".\", text.strip())\n",
    "    return text.strip()\n",
    "\n",
    "def generate_answer(question, header1, header2, content):\n",
    "    prompt = f\"\"\"\n",
    "    너는 AI 최신 기술 리포트를 분석하는 LLM 엔지니어다.\n",
    "    문서 주제: {header1} - {header2 if header2 else \"\"}\n",
    "    본문 내용 (발췌): {content[:3000] if content else \"\"}\n",
    "\n",
    "    [요구사항]\n",
    "    - 아래 질문에 대해 보고서 본문을 근거로 심층적인 답변을 작성하라.\n",
    "    - 답변은 연구 보고서 스타일로 작성하며, 3~4문단으로 구성하라.\n",
    "    - 전체 분량은 800~1000자 내외가 되도록 하라.\n",
    "    - 각 문단은 완결된 문장으로 끝내라.\n",
    "    - 서론(질문의 중요성), 본론(기술적 근거·세부 분석), 결론(핵심 요약과 시사점) 구조를 따르라.\n",
    "    - 마지막 문장은 반드시 마침표 하나(.)로 끝내라. 불필요한 ... 은 쓰지 말라.\n",
    "    - 출력은 반드시 '답변: ' 형식으로 하라.\n",
    "    - 최종 답변은 반드시 마침표 하나(.)로 끝내라.\n",
    "    - '...' 나 불필요한 반복 마침표는 절대 사용하지 말라.\n",
    "\n",
    "\n",
    "    질문: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\"max_output_tokens\": 9096, \"temperature\": 0.7}\n",
    "        )\n",
    "\n",
    "        if response.candidates and response.candidates[0].content.parts:\n",
    "            answer = response.candidates[0].content.parts[0].text.strip()\n",
    "        else:\n",
    "            answer = \"[⚠️ 답변 없음: 토큰 한도 초과 또는 안전 필터 차단]\"\n",
    "\n",
    "    except Exception as e:\n",
    "        answer = f\"[⚠️ 에러 발생: {str(e)}]\"\n",
    "\n",
    "    # 후처리: 결론 보강\n",
    "    if not answer.endswith((\"이다.\", \"있다.\", \"할 수 있다.\")):\n",
    "        try:\n",
    "            fix_prompt = f\"\"\"\n",
    "            다음 답변이 결론 없이 끝났습니다. \n",
    "            불필요한 멘트(예: '네, 알겠습니다', '물론입니다', '다음은', '### 결론', '***')는 쓰지 말고, \n",
    "            보고서 스타일의 결론 문단(3~4문장)을 작성하세요. 마지막 문장은 반드시 마침표 하나(.)로 끝내라.\n",
    "\n",
    "            불완전 답변: {answer}\n",
    "            \"\"\"\n",
    "            fix_response = model.generate_content(fix_prompt)\n",
    "            if fix_response.candidates and fix_response.candidates[0].content.parts:\n",
    "                answer += \"\\n\\n\" + fix_response.candidates[0].content.parts[0].text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 마지막 정리 (멘트/###/*** 제거, ... → .)\n",
    "    return clean_answer_text(answer) or \"\"\n",
    "\n",
    "for i, q in enumerate(questions):  # 전체 다 돌림\n",
    "    h1, h2, question = q[\"Header 1\"], q[\"Header 2\"], q[\"Question\"]\n",
    "\n",
    "    # md_header_splits에서 헤더 매칭해서 본문 불러오기\n",
    "    content = \"\"\n",
    "    for doc in md_header_splits:\n",
    "        if doc.metadata.get(\"Header 1\") == h1 and doc.metadata.get(\"Header 2\") == h2:\n",
    "            content = doc.page_content\n",
    "            break\n",
    "\n",
    "    answer = generate_answer(question, h1, h2, content)\n",
    "    q[\"Answer\"] = answer  # 답변 추가\n",
    "\n",
    "    print(f\"\\nQ{i+1}/{len(questions)}: {question}\")\n",
    "    print(f\"A: {answer[:]}...\")  # 앞부분만 미리보기 \n",
    "    \n",
    "    \n",
    "    \n",
    "import csv\n",
    "\n",
    "output_path = \"techreader_data/header_based_questions_with_answers.csv\"\n",
    "\n",
    "with open(output_path, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    fieldnames = [\"Header 1\", \"Header 2\", \"Question\", \"Answer\"]\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for q in questions:\n",
    "        writer.writerow({\n",
    "            \"Header 1\": q[\"Header 1\"],\n",
    "            \"Header 2\": q[\"Header 2\"],\n",
    "            \"Question\": q[\"Question\"],\n",
    "            \"Answer\": q.get(\"Answer\", \"\")\n",
    "        })\n",
    "\n",
    "print(f\"✅ 최종 저장 완료: {output_path}\")\n",
    "\n",
    "# 예상 질문 답변 쌍 저장 완료 (CSV 파일 2개) \n",
    "\n",
    "\n",
    "# 위의 paraphrase된 질문에는 질문을 포함한 광범위한 내용이 담겨 필터링 필요 - 우선 시범 테스트 진행 \n",
    "import pandas as pd\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Gemini 초기화\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "def generate_paraphrases(question, n=5):\n",
    "    prompt = f\"\"\"\n",
    "    다음 질문을 의미가 동일하지만 표현이 다른 방식으로 {n}개 만들어줘.\n",
    "    출력은 반드시 질문만, 각 줄 하나씩, 불필요한 설명이나 번호, 불릿, 마크다운 기호 없이 작성해.\n",
    "    질문: {question}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        if response.candidates and response.candidates[0].content.parts:\n",
    "            text = response.candidates[0].content.parts[0].text.strip()\n",
    "            # 줄 단위 split\n",
    "            lines = [line.strip(\" -•0123456789.\") for line in text.split(\"\\n\") if line.strip()]\n",
    "            # \"?\" 로 끝나는 질문만 남김\n",
    "            paras = [line for line in lines if line.endswith(\"?\")]\n",
    "            return paras\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 오류 발생: {e}\")\n",
    "    return []\n",
    "\n",
    "# 원본 CSV 로드\n",
    "input_path = \"techreader_data/content_based_questions_with_answers.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# 상위 3개 질문만 테스트\n",
    "sample_questions = df[\"Question\"].head(3).tolist()\n",
    "\n",
    "print(\"🔹 Paraphrase 생성 테스트 (3개 질문)\\n\")\n",
    "for i, q in enumerate(sample_questions, start=1):\n",
    "    paras = generate_paraphrases(q, n=3)\n",
    "    print(f\"Q{i}: {q}\")\n",
    "    for j, p in enumerate(paras, start=1):\n",
    "        print(f\"   → P{j}: {p}\") \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Gemini 초기화\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "def generate_paraphrases(question, n=4):\n",
    "    prompt = f\"\"\"\n",
    "    다음 질문을 의미가 동일하지만 표현이 다른 방식으로 {n}개 만들어줘.\n",
    "    출력은 반드시 질문만, 각 줄 하나씩, 불필요한 설명이나 번호, 불릿, 마크다운 기호 없이 작성해.\n",
    "    질문: {question}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        if response.candidates and response.candidates[0].content.parts:\n",
    "            text = response.candidates[0].content.parts[0].text.strip()\n",
    "            lines = [line.strip(\" -•0123456789.\") for line in text.split(\"\\n\") if line.strip()]\n",
    "            paras = [line for line in lines if line.endswith(\"?\")]  # 질문만\n",
    "            return paras\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 오류 발생: {e}\")\n",
    "    return []\n",
    "\n",
    "# 원본 CSV 로드\n",
    "input_path = \"techreader_data/content_based_questions_with_answers.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Paraphrases 생성\n",
    "df[\"Paraphrases\"] = df[\"Question\"].apply(lambda q: generate_paraphrases(q, n=4))\n",
    "\n",
    "# 새 파일로 저장\n",
    "output_path = \"techreader_data/content_based_FAQ2_with_paraphrases.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ Paraphrases 추가 완료: {output_path}\")\n",
    "\n",
    "# TechReader_gayoon/techreader_data/header_based_questions_with_answers.csv \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Gemini 초기화\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "def generate_paraphrases(question, n=4):\n",
    "    prompt = f\"\"\"\n",
    "    다음 질문을 의미가 동일하지만 표현이 다른 방식으로 {n}개 만들어줘.\n",
    "    출력은 반드시 질문만, 각 줄 하나씩, 불필요한 설명이나 번호, 불릿, 마크다운 기호 없이 작성해.\n",
    "    질문: {question}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        if response.candidates and response.candidates[0].content.parts:\n",
    "            text = response.candidates[0].content.parts[0].text.strip()\n",
    "            lines = [line.strip(\" -•0123456789.\") for line in text.split(\"\\n\") if line.strip()]\n",
    "            paras = [line for line in lines if line.endswith(\"?\")]  # 질문만\n",
    "            return paras\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 오류 발생: {e}\")\n",
    "    return []\n",
    "\n",
    "# 원본 CSV 로드\n",
    "input_path = \"techreader_data/header_based_questions_with_answers.csv \"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Paraphrases 생성\n",
    "df[\"Paraphrases\"] = df[\"Question\"].apply(lambda q: generate_paraphrases(q, n=4))\n",
    "\n",
    "# 새 파일로 저장\n",
    "output_path = \"techreader_data/header_based_FAQ2_with_paraphrases.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ Paraphrases 추가 완료: {output_path}\")\n",
    "\n",
    "\n",
    "faq 질문 답변쌍은 CacheBackedEmbeddings 사용 \n",
    "일반 질문 답변쌍은 업스테이지 임베딩 모델 사용 \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from pathlib import Path\n",
    "\n",
    "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\", api_key=\"UPSTAGE_API_KEY\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1. FAQ 데이터 (CacheBackedEmbeddings)\n",
    "# ----------------------------\n",
    "def load_faq_docs(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    docs = []\n",
    "    for _, row in df.iterrows():\n",
    "        base_q = row[\"Question\"]\n",
    "        paras = []\n",
    "        try:\n",
    "            paras = ast.literal_eval(row[\"Paraphrases\"])\n",
    "        except:\n",
    "            pass\n",
    "        all_qs = [base_q] + paras\n",
    "        for q in all_qs:\n",
    "            docs.append(Document(\n",
    "                page_content=q,\n",
    "                metadata={\"Answer\": row[\"Answer\"],\n",
    "                          \"Header 1\": row.get(\"Header 1\", \"\"),\n",
    "                          \"Header 2\": row.get(\"Header 2\", \"\")}\n",
    "            ))\n",
    "    return docs\n",
    "\n",
    "faq_files = [\n",
    "    \"techreader_data/header_based_FAQ2_with_paraphrases.csv\",\n",
    "    \"techreader_data/content_based_FAQ2_with_paraphrases.csv\"\n",
    "]\n",
    "\n",
    "faq_docs = []\n",
    "for f in faq_files:\n",
    "    faq_docs.extend(load_faq_docs(f))\n",
    "\n",
    "# 캐시 디렉토리\n",
    "cache_dir = Path(\"techreader_data/faq_cache\")\n",
    "store = LocalFileStore(str(cache_dir))\n",
    "\n",
    "# 기본 임베딩\n",
    "base_embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# CacheBackedEmbeddings 구성\n",
    "faq_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=base_embeddings,\n",
    "    document_embedding_cache=store\n",
    ")\n",
    "\n",
    "faq_db = FAISS.from_documents(faq_docs, faq_embeddings)\n",
    "faq_db.save_local(\"techreader_data/faq_index\")\n",
    "faq_retriever = faq_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "print(\"✅ FAQ Retriever 준비 완료\")\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "from langchain.schema import Document\n",
    "\n",
    "chunks_df = pd.read_csv(\"techreader_data/chunks_output.csv\")\n",
    "\n",
    "chunk_docs = []\n",
    "for _, row in chunks_df.iterrows():\n",
    "    content = row[\"Content\"]\n",
    "\n",
    "    # Metadata 문자열 → dict 변환\n",
    "    metadata = {}\n",
    "    if isinstance(row[\"Metadata\"], str) and row[\"Metadata\"].strip() != \"{}\":\n",
    "        try:\n",
    "            metadata = ast.literal_eval(row[\"Metadata\"])\n",
    "        except Exception:\n",
    "            metadata = {\"raw_metadata\": row[\"Metadata\"]}\n",
    "\n",
    "    # Chunk 번호도 추가\n",
    "    metadata[\"Chunk No\"] = row[\"Chunk No\"]\n",
    "\n",
    "    chunk_docs.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "print(f\"✅ 총 {len(chunk_docs)}개 chunk 변환 완료\")\n",
    "print(\"예시 Document:\", chunk_docs[0])\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_upstage import UpstageEmbeddings  # pip install langchain-upstage\n",
    "\n",
    "# Upstage 임베딩 초기화\n",
    "chunk_embeddings = UpstageEmbeddings(\n",
    "    model=\"solar-embedding-1-large\", \n",
    "    api_key=os.environ[\"UPSTAGE_API_KEY\"]\n",
    ")\n",
    "\n",
    "# FAISS 인덱스 구축\n",
    "chunk_db = FAISS.from_documents(chunk_docs, chunk_embeddings)\n",
    "\n",
    "# 로컬 저장\n",
    "chunk_db.save_local(\"techreader_data/chunk_index\")\n",
    "\n",
    "# Retriever\n",
    "chunk_retriever = chunk_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "print(\"✅ Chunk Retriever 준비 완료\")\n",
    "\n",
    "\n",
    "query = \"교사와 학생 모델의 차이점은 무엇인가?\"\n",
    "\n",
    "response = hybrid_search(query, faq_retriever, chunk_retriever)\n",
    "print(response)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
