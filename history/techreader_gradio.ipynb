{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ff0ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7881\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7881/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SBA\\AppData\\Local\\Temp\\ipykernel_21244\\1974990632.py:62: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = faq_retriever.get_relevant_documents(user_query)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 1. CSV ë¡œë“œ\n",
    "df = pd.read_csv(\"techreader_data/content_based_questions_with_answers.csv\")\n",
    "\n",
    "# 2. FAQ ì¸ë±ìŠ¤ ìƒì„±\n",
    "embeddings = OpenAIEmbeddings()\n",
    "faq_docs = [\n",
    "    Document(page_content=row[\"Question\"], metadata=row.to_dict())\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "faq_db = FAISS.from_documents(faq_docs, embeddings)\n",
    "faq_retriever = faq_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# 3. 'ë‹µë³€:' ì ‘ë‘ì‚¬ ì œê±° í•¨ìˆ˜\n",
    "def clean_answer(text: str) -> str:\n",
    "    if text.strip().startswith(\"ë‹µë³€\"):\n",
    "        return text.split(\":\", 1)[-1].strip()\n",
    "    return text.strip()\n",
    "\n",
    "# 4. ì§ˆë¬¸ í›„ì²˜ë¦¬ í•¨ìˆ˜ (**í…ìŠ¤íŠ¸** ì œê±°, > ì œê±°)\n",
    "def clean_question(q: str) -> str:\n",
    "    # 1) **í…ìŠ¤íŠ¸** â†’ í…ìŠ¤íŠ¸\n",
    "    q = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\1\", q)\n",
    "    # 2) ** í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸  (ì•ì— ** + ê³µë°± ì œê±°)\n",
    "    q = re.sub(r\"\\*\\*\\s*\", \"\", q)\n",
    "    # 3) > í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸\n",
    "    q = re.sub(r\"^\\s*>\\s*\", \"\", q)\n",
    "    return q.strip()\n",
    "\n",
    "\n",
    "\n",
    "# 5. ì¹´ë“œ ìŠ¤íƒ€ì¼ FAQ í…œí”Œë¦¿\n",
    "def format_faq_card(q, a, h1=\"\", h2=\"\"):\n",
    "    return f\"\"\"\n",
    "    <div style=\"margin:15px 10px; border:1px solid #ddd; border-radius:10px; overflow:hidden;\">\n",
    "      <!-- ì§ˆë¬¸ ì˜ì—­ -->\n",
    "      <details>\n",
    "        <summary style=\"padding:12px; background:#f5f5f5; cursor:pointer; display:flex; align-items:center;\">\n",
    "          <div style=\"background:#1976d2; color:white; font-weight:bold;\n",
    "                      border-radius:50%; width:32px; height:32px;\n",
    "                      display:flex; align-items:center; justify-content:center;\n",
    "                      margin-right:10px; font-size:16px; line-height:32px;\">Q</div>\n",
    "          <span style=\"font-weight:bold; font-size:16px;\">{q}</span>\n",
    "        </summary>\n",
    "        \n",
    "        <!-- ë‹µë³€ ì˜ì—­ -->\n",
    "        <div style=\"padding:15px; background:white; font-size:15px; line-height:1.6;\">\n",
    "          {a}\n",
    "        </div>\n",
    "      </details>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "# 6. FAQ ê²€ìƒ‰\n",
    "def search_faq(user_query):\n",
    "    results = faq_retriever.get_relevant_documents(user_query)\n",
    "    outputs = []\n",
    "    for r in results:\n",
    "        q = clean_question(r.page_content)         # âœ… ì§ˆë¬¸ í›„ì²˜ë¦¬ ì ìš©\n",
    "        a = clean_answer(r.metadata[\"Answer\"])     # âœ… ë‹µë³€ í›„ì²˜ë¦¬ ì ìš©\n",
    "        h1 = r.metadata.get(\"Header 1\", \"\")\n",
    "        h2 = r.metadata.get(\"Header 2\", \"\")\n",
    "        outputs.append(format_faq_card(q, a, h1, h2))\n",
    "    return \"\".join(outputs)\n",
    "\n",
    "# 7. FAQ ì „ì²´ ë³´ê¸°\n",
    "def show_faq():\n",
    "    grouped = df.groupby(\"Header 1\")\n",
    "    html_blocks = []\n",
    "    for h1, group in grouped:\n",
    "        html_blocks.append(f\"<h2 style='color:#1976d2; margin-top:40px;'>ğŸ“˜ {h1}</h2>\")\n",
    "        sub_group = group.groupby(\"Header 2\")\n",
    "        for h2, rows in sub_group:\n",
    "            if h2 and h2 != \"nan\":\n",
    "                html_blocks.append(f\"<h3 style='color:#444; margin-top:20px;'>ğŸ“Œ {h2}</h3>\")\n",
    "            for _, row in rows.iterrows():\n",
    "                q = clean_question(row[\"Question\"])  # âœ… ì§ˆë¬¸ í›„ì²˜ë¦¬ ì ìš©\n",
    "                a = clean_answer(row[\"Answer\"])      # âœ… ë‹µë³€ í›„ì²˜ë¦¬ ì ìš©\n",
    "                html_blocks.append(format_faq_card(q, a, h1, h2))\n",
    "    return \"\".join(html_blocks)\n",
    "\n",
    "# 8. Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ğŸ“˜ Tech Library FAQ ë·°ì–´\")\n",
    "\n",
    "    with gr.Tab(\"FAQ ê²€ìƒ‰\"):\n",
    "        query = gr.Textbox(label=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "        output = gr.HTML()\n",
    "        query.submit(search_faq, query, output)\n",
    "\n",
    "    with gr.Tab(\"FAQ ì „ì²´ ë³´ê¸°\"):\n",
    "        faq_output = gr.HTML(show_faq())\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32250f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TechReader_gayoon\\techreader_data\\header_based_FAQ2_with_paraphrases.csv \n",
    "# TechReader_gayoon\\techreader_data\\content_based_FAQ2_with_paraphrases.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed0fe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7882\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# -----------------------------\n",
    "# 1. CSV ë¡œë“œ (ë‘ íŒŒì¼ í•©ì¹˜ê¸°)\n",
    "# -----------------------------\n",
    "df_header = pd.read_csv(\"techreader_data/header_based_FAQ2_with_paraphrases.csv\")\n",
    "df_content = pd.read_csv(\"techreader_data/content_based_FAQ2_with_paraphrases.csv\")\n",
    "\n",
    "# í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (êµ¬ë¶„ ì»¬ëŸ¼ ì¶”ê°€)\n",
    "df_header[\"Source\"] = \"Header-based\"\n",
    "df_content[\"Source\"] = \"Content-based\"\n",
    "df = pd.concat([df_header, df_content], ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. FAQ ì¸ë±ìŠ¤ ìƒì„±\n",
    "# -----------------------------\n",
    "embeddings = OpenAIEmbeddings()\n",
    "faq_docs = [\n",
    "    Document(page_content=row[\"Question\"], metadata=row.to_dict())\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "faq_db = FAISS.from_documents(faq_docs, embeddings)\n",
    "faq_retriever = faq_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. í›„ì²˜ë¦¬ í•¨ìˆ˜\n",
    "# -----------------------------\n",
    "def clean_answer(text: str) -> str:\n",
    "    \"\"\"'ë‹µë³€:' ì ‘ë‘ì‚¬ ì œê±°\"\"\"\n",
    "    if isinstance(text, str) and text.strip().startswith(\"ë‹µë³€\"):\n",
    "        return text.split(\":\", 1)[-1].strip()\n",
    "    return str(text).strip()\n",
    "\n",
    "def clean_question(q: str) -> str:\n",
    "    \"\"\"ì§ˆë¬¸ì—ì„œ **í…ìŠ¤íŠ¸** íŒ¨í„´, > ê¸°í˜¸ ì œê±°\"\"\"\n",
    "    if not isinstance(q, str):\n",
    "        return \"\"\n",
    "    q = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\1\", q)   # **í…ìŠ¤íŠ¸** â†’ í…ìŠ¤íŠ¸\n",
    "    q = re.sub(r\"\\*\\*\\s*\", \"\", q)            # ** í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸\n",
    "    q = re.sub(r\"^\\s*>\\s*\", \"\", q)           # > í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸\n",
    "    return q.strip()\n",
    "\n",
    "# -----------------------------\n",
    "# 4. ì¹´ë“œ ìŠ¤íƒ€ì¼ FAQ í…œí”Œë¦¿\n",
    "# -----------------------------\n",
    "def format_faq_card(q, a, h1=\"\", h2=\"\", source=\"\"):\n",
    "    return f\"\"\"\n",
    "    <div style=\"margin:15px 10px; border:1px solid #ddd; border-radius:10px; overflow:hidden;\">\n",
    "      <details>\n",
    "        <summary style=\"padding:12px; background:#f5f5f5; cursor:pointer; display:flex; align-items:center;\">\n",
    "          <div style=\"background:#1976d2; color:white; font-weight:bold;\n",
    "                      border-radius:50%; width:32px; height:32px;\n",
    "                      display:flex; align-items:center; justify-content:center;\n",
    "                      margin-right:10px; font-size:16px; line-height:32px;\">Q</div>\n",
    "          <span style=\"font-weight:bold; font-size:16px;\">{q}</span>\n",
    "        </summary>\n",
    "        <div style=\"padding:15px; background:white; font-size:15px; line-height:1.6;\">\n",
    "          {a}\n",
    "          <br><br><span style=\"color:#666; font-size:13px;\">ì¶œì²˜: {h1} > {h2} ({source})</span>\n",
    "        </div>\n",
    "      </details>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 5. FAQ ê²€ìƒ‰\n",
    "# -----------------------------\n",
    "def search_faq(user_query):\n",
    "    results = faq_retriever.get_relevant_documents(user_query)\n",
    "    outputs = []\n",
    "    for r in results:\n",
    "        q = clean_question(r.page_content)\n",
    "        a = clean_answer(r.metadata.get(\"Answer\", \"\"))\n",
    "        h1 = r.metadata.get(\"Header 1\", \"\")\n",
    "        h2 = r.metadata.get(\"Header 2\", \"\")\n",
    "        source = r.metadata.get(\"Source\", \"\")\n",
    "        outputs.append(format_faq_card(q, a, h1, h2, source))\n",
    "    return \"\".join(outputs)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. FAQ ì „ì²´ ë³´ê¸°\n",
    "# -----------------------------\n",
    "def show_faq():\n",
    "    grouped = df.groupby(\"Header 1\")\n",
    "    html_blocks = []\n",
    "    for h1, group in grouped:\n",
    "        html_blocks.append(f\"<h2 style='color:#1976d2; margin-top:40px;'>ğŸ“˜ {h1}</h2>\")\n",
    "        sub_group = group.groupby(\"Header 2\")\n",
    "        for h2, rows in sub_group:\n",
    "            if h2 and h2 != \"nan\":\n",
    "                html_blocks.append(f\"<h3 style='color:#444; margin-top:20px;'>ğŸ“Œ {h2}</h3>\")\n",
    "            for _, row in rows.iterrows():\n",
    "                q = clean_question(row[\"Question\"])\n",
    "                a = clean_answer(row[\"Answer\"])\n",
    "                source = row.get(\"Source\", \"\")\n",
    "                html_blocks.append(format_faq_card(q, a, h1, h2, source))\n",
    "    return \"\".join(html_blocks)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Gradio UI\n",
    "# -----------------------------\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ğŸ“˜ Tech Library FAQ ë·°ì–´\")\n",
    "\n",
    "    with gr.Tab(\"FAQ ê²€ìƒ‰\"):\n",
    "        query = gr.Textbox(label=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "        output = gr.HTML()\n",
    "        query.submit(search_faq, query, output)\n",
    "\n",
    "    with gr.Tab(\"FAQ ì „ì²´ ë³´ê¸°\"):\n",
    "        faq_output = gr.HTML(show_faq())\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697c54e",
   "metadata": {},
   "source": [
    "# Gradio : FAQ + ì¼ë°˜ ê²€ìƒ‰ í†µí•© ë·°ì–´ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd44157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SBA\\AppData\\Local\\Temp\\ipykernel_3388\\686993562.py:205: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chunk_results = chunk_retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# -----------------------------\n",
    "# Gemini ì´ˆê¸°í™” (ë¬¸ì„œ ë‹µë³€ìš©)\n",
    "# -----------------------------\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1. CSV ë¡œë“œ (FAQ: header+content)\n",
    "# -----------------------------\n",
    "df_header = pd.read_csv(\"techreader_data/header_based_FAQ2_with_paraphrases.csv\")\n",
    "df_content = pd.read_csv(\"techreader_data/content_based_FAQ2_with_paraphrases.csv\")\n",
    "df_header[\"Source\"] = \"Header-based\"\n",
    "df_content[\"Source\"] = \"Content-based\"\n",
    "df_faq = pd.concat([df_header, df_content], ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. FAQ ì¸ë±ìŠ¤ ìƒì„±\n",
    "# -----------------------------\n",
    "embeddings = OpenAIEmbeddings()\n",
    "faq_docs = [\n",
    "    Document(page_content=row[\"Question\"], metadata=row.to_dict())\n",
    "    for _, row in df_faq.iterrows()\n",
    "]\n",
    "faq_db = FAISS.from_documents(faq_docs, embeddings)\n",
    "faq_retriever = faq_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Chunk ì¸ë±ìŠ¤ ìƒì„± (ì›ë¬¸ ê²€ìƒ‰ìš©)\n",
    "# -----------------------------\n",
    "chunks_df = pd.read_csv(\"techreader_data/chunks_output.csv\")\n",
    "\n",
    "chunk_docs = [\n",
    "    Document(\n",
    "        page_content=row[\"Content\"],\n",
    "        metadata={\"Chunk No\": row[\"Chunk No\"], **eval(row[\"Metadata\"])}\n",
    "    )\n",
    "    for _, row in chunks_df.iterrows()\n",
    "]\n",
    "chunk_db = FAISS.from_documents(chunk_docs, embeddings)\n",
    "chunk_retriever = chunk_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# -----------------------------\n",
    "# 4. í›„ì²˜ë¦¬ í•¨ìˆ˜\n",
    "# -----------------------------\n",
    "def clean_answer(text: str) -> str:\n",
    "    if isinstance(text, str) and text.strip().startswith(\"ë‹µë³€\"):\n",
    "        return text.split(\":\", 1)[-1].strip()\n",
    "    return str(text).strip()\n",
    "\n",
    "def clean_question(q: str) -> str:\n",
    "    if not isinstance(q, str):\n",
    "        return \"\"\n",
    "    q = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\1\", q)   # **í…ìŠ¤íŠ¸** â†’ í…ìŠ¤íŠ¸\n",
    "    q = re.sub(r\"\\*\\*\\s*\", \"\", q)            # ** í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸\n",
    "    q = re.sub(r\"^\\s*>\\s*\", \"\", q)           # > í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸\n",
    "    return q.strip()\n",
    "\n",
    "# -----------------------------\n",
    "# 5. ì¹´ë“œ ìŠ¤íƒ€ì¼ FAQ í…œí”Œë¦¿\n",
    "# -----------------------------\n",
    "def format_faq_card(q, a, h1=\"\", h2=\"\", source=\"\"):\n",
    "    return f\"\"\"\n",
    "    <div style=\"margin:15px 10px; border:1px solid #ddd; border-radius:10px; overflow:hidden;\">\n",
    "      <details>\n",
    "        <summary style=\"padding:12px; background:#f5f5f5; cursor:pointer; display:flex; align-items:center;\">\n",
    "          <div style=\"background:#1976d2; color:white; font-weight:bold;\n",
    "                      border-radius:50%; width:32px; height:32px;\n",
    "                      display:flex; align-items:center; justify-content:center;\n",
    "                      margin-right:10px; font-size:16px; line-height:32px;\">Q</div>\n",
    "          <span style=\"font-weight:bold; font-size:16px;\">{q}</span>\n",
    "        </summary>\n",
    "        <div style=\"padding:15px; background:white; font-size:15px; line-height:1.6;\">\n",
    "          {a}\n",
    "          <br><br><span style=\"color:#666; font-size:13px;\">ì¶œì²˜: {h1} > {h2} ({source})</span>\n",
    "        </div>\n",
    "      </details>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. FAQ ê²€ìƒ‰\n",
    "# -----------------------------\n",
    "def search_faq(user_query):\n",
    "    results = faq_retriever.get_relevant_documents(user_query)\n",
    "    outputs = []\n",
    "    for r in results:\n",
    "        q = clean_question(r.page_content)\n",
    "        a = clean_answer(r.metadata.get(\"Answer\", \"\"))\n",
    "        h1 = r.metadata.get(\"Header 1\", \"\")\n",
    "        h2 = r.metadata.get(\"Header 2\", \"\")\n",
    "        source = r.metadata.get(\"Source\", \"\")\n",
    "        outputs.append(format_faq_card(q, a, h1, h2, source))\n",
    "    return \"\".join(outputs)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. FAQ ì „ì²´ ë³´ê¸°\n",
    "# -----------------------------\n",
    "def show_faq():\n",
    "    grouped = df_faq.groupby(\"Header 1\")\n",
    "    html_blocks = []\n",
    "    for h1, group in grouped:\n",
    "        html_blocks.append(f\"<h2 style='color:#1976d2; margin-top:40px;'>ğŸ“˜ {h1}</h2>\")\n",
    "        sub_group = group.groupby(\"Header 2\")\n",
    "        for h2, rows in sub_group:\n",
    "            if h2 and h2 != \"nan\":\n",
    "                html_blocks.append(f\"<h3 style='color:#444; margin-top:20px;'>ğŸ“Œ {h2}</h3>\")\n",
    "            for _, row in rows.iterrows():\n",
    "                q = clean_question(row[\"Question\"])\n",
    "                a = clean_answer(row[\"Answer\"])\n",
    "                source = row.get(\"Source\", \"\")\n",
    "                html_blocks.append(format_faq_card(q, a, h1, h2, source))\n",
    "    return \"\".join(html_blocks)\n",
    "\n",
    "# -----------------------------\n",
    "# 8. ì¼ë°˜ ê²€ìƒ‰ (Chunk ê¸°ë°˜, LLM ë‹¤ë“¬ê¸°)\n",
    "# -----------------------------\n",
    "def chunk_answer(query, retrieved_docs):\n",
    "    docs_text = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"[Chunk {doc.metadata.get('Chunk No')}] \"\n",
    "            f\"(Header1: {doc.metadata.get('Header 1','')}, \"\n",
    "            f\"Header2: {doc.metadata.get('Header 2','')}, \"\n",
    "            f\"Header3: {doc.metadata.get('Header 3','')})\\n\"\n",
    "            f\"{doc.page_content}\"\n",
    "            for doc in retrieved_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    ë„ˆëŠ” ì—°êµ¬ ë³´ê³ ì„œë¥¼ ìš”ì•½í•˜ëŠ” LLM ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤. \n",
    "    ì•„ë˜ ë¬¸ì„œ ì¡°ê°ë“¤ë§Œ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì‘ì„±í•˜ë¼. \n",
    "\n",
    "    [ìš”êµ¬ì‚¬í•­]\n",
    "    - ë¬¸ì„œ ë‚´ìš©ë§Œ í™œìš©í•  ê²ƒ (ìƒˆë¡œìš´ ì‚¬ì‹¤ ìƒì„± ê¸ˆì§€).\n",
    "    - ë‹µë³€ì€ 3~4ë¬¸ë‹¨, 600~800ì ë‚´ì™¸ë¡œ ì •ë¦¬.\n",
    "    - ê²°ë¡  ë¬¸ë‹¨ì€ ë°˜ë“œì‹œ 'ë”°ë¼ì„œ, ~ì´ë‹¤.' ë˜ëŠ” 'ê²°ë¡ ì ìœ¼ë¡œ, ~ë¼ê³  í•  ìˆ˜ ìˆë‹¤.' í˜•íƒœë¡œ ë§ˆë¬´ë¦¬.\n",
    "    - ë‹µë³€ í›„ ë°˜ë“œì‹œ \"ì¶œì²˜\" ì„¹ì…˜ì„ ì¶”ê°€í•˜ì—¬ ì‚¬ìš©í•œ Header1/2/3ì™€ Chunk Noë¥¼ ë‚˜ì—´í•  ê²ƒ.\n",
    "    - ì¶œë ¥ì€ ë°˜ë“œì‹œ HTML ì¹´ë“œ í˜•íƒœë¡œ (FAQ ì¹´ë“œ ìŠ¤íƒ€ì¼) ë°˜í™˜.\n",
    "\n",
    "    ì§ˆë¬¸: {query}\n",
    "\n",
    "    ë¬¸ì„œ ì¡°ê°:\n",
    "    {docs_text}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\"max_output_tokens\": 9000, \"temperature\": 0.5}\n",
    "        )\n",
    "\n",
    "        if response.candidates and response.candidates[0].content.parts:\n",
    "            answer = \"\".join(\n",
    "                [p.text for p in response.candidates[0].content.parts if hasattr(p, \"text\")]\n",
    "            ).strip()\n",
    "        else:\n",
    "            answer = \"[âš ï¸ ë‹µë³€ ì—†ìŒ: ëª¨ë¸ì´ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ì•ŠìŒ]\"\n",
    "\n",
    "    except Exception as e:\n",
    "        answer = f\"[âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}]\" \n",
    "        \n",
    "    # âœ… í›„ì²˜ë¦¬: ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±°\n",
    "    answer = answer.replace(\"```html\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "    # âœ… ì¤„ë°”ê¿ˆì„ HTML <br>ë¡œ ì¹˜í™˜ (f-string ë°–ì—ì„œ)\n",
    "    answer_html = answer.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "    # ğŸ“Œ ì¹´ë“œ UI ìŠ¤íƒ€ì¼ ê°ì‹¸ê¸°\n",
    "    return (\n",
    "        \"<div style='margin:15px 10px; border:1px solid #ddd; border-radius:10px; overflow:hidden;'>\"\n",
    "        \"<div style='padding:12px; background:#f5f5f5; font-weight:bold; font-size:16px;'>ğŸ“‘ ë¬¸ì„œ ê¸°ë°˜ ì‘ë‹µ</div>\"\n",
    "        f\"<div style='padding:15px; background:white; font-size:15px; line-height:1.6;'>{answer_html}</div>\"\n",
    "        \"</div>\"\n",
    "    )\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Hybrid Search í•¨ìˆ˜ ì •ì˜ (UIë³´ë‹¤ ìœ„ì— ìˆì–´ì•¼ í•¨)\n",
    "# -----------------------------\n",
    "FAQ_THRESHOLD = 0.7  # ì‹ ë¢°ë„ ê¸°ì¤€ê°’\n",
    "\n",
    "def hybrid_search(query, faq_retriever, chunk_retriever):\n",
    "    # FAQ ê²€ìƒ‰\n",
    "    faq_results = []\n",
    "    try:\n",
    "        faq_results = faq_retriever.vectorstore.similarity_search_with_score(query, k=3)\n",
    "    except Exception:\n",
    "        faq_results = [(doc, 1.0) for doc in faq_retriever.get_relevant_documents(query)[:3]]\n",
    "\n",
    "    faq_outputs = []\n",
    "    for doc, score in faq_results:\n",
    "        if score >= FAQ_THRESHOLD:\n",
    "            faq_outputs.append(format_faq_answer(doc))\n",
    "\n",
    "    # Chunk ê²€ìƒ‰ (í•­ìƒ ë©”ì¸)\n",
    "    chunk_results = chunk_retriever.get_relevant_documents(query)\n",
    "    chunk_output = chunk_answer(query, chunk_results) if chunk_results else \"âš ï¸ Chunk ê¸°ë°˜ ê²°ê³¼ ì—†ìŒ\"\n",
    "\n",
    "\n",
    "    # í•©ì¹˜ê¸°\n",
    "    if faq_outputs:\n",
    "        faq_block = \"\\n\\n\".join(faq_outputs)\n",
    "        return f\"{chunk_output}\\n\\n---\\n\\n{faq_block}\"\n",
    "    else:\n",
    "        return chunk_output\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Gradio UI \n",
    "# -----------------------------\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ğŸ“˜ Tech Library ê²€ìƒ‰ ë·°ì–´\")\n",
    "\n",
    "    with gr.Tab(\"ì¼ë°˜ ê²€ìƒ‰ (ë¬¸ì„œ ê¸°ë°˜)\"):\n",
    "        query2 = gr.Textbox(label=\"ì¼ë°˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "        output2 = gr.HTML()\n",
    "        query2.submit(lambda q: hybrid_search(q, faq_retriever, chunk_retriever), query2, output2)\n",
    "\n",
    "    with gr.Tab(\"FAQ ê²€ìƒ‰\"):\n",
    "        query = gr.Textbox(label=\"FAQ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "        output = gr.HTML()\n",
    "        query.submit(search_faq, query, output)\n",
    "\n",
    "    with gr.Tab(\"FAQ ì „ì²´ ë³´ê¸°\"):\n",
    "        faq_output = gr.HTML(show_faq())\n",
    "\n",
    "demo.launch() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8f9e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# -----------------------------\n",
    "# Gemini ì´ˆê¸°í™” (ë¬¸ì„œ ë‹µë³€ìš©)\n",
    "# -----------------------------\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1. CSV ë¡œë“œ (FAQ: header+content)\n",
    "# -----------------------------\n",
    "df_header = pd.read_csv(\"techreader_data/header_based_FAQ2_with_paraphrases.csv\")\n",
    "df_content = pd.read_csv(\"techreader_data/content_based_FAQ2_with_paraphrases.csv\")\n",
    "df_header[\"Source\"] = \"Header-based\"\n",
    "df_content[\"Source\"] = \"Content-based\"\n",
    "df_faq = pd.concat([df_header, df_content], ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. FAQ ì¸ë±ìŠ¤ ìƒì„±\n",
    "# -----------------------------\n",
    "embeddings = OpenAIEmbeddings()\n",
    "faq_docs = [\n",
    "    Document(page_content=row[\"Question\"], metadata=row.to_dict())\n",
    "    for _, row in df_faq.iterrows()\n",
    "]\n",
    "faq_db = FAISS.from_documents(faq_docs, embeddings)\n",
    "faq_retriever = faq_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Chunk ì¸ë±ìŠ¤ ìƒì„± (ì›ë¬¸ ê²€ìƒ‰ìš©)\n",
    "# -----------------------------\n",
    "chunks_df = pd.read_csv(\"techreader_data/chunks_output.csv\")\n",
    "\n",
    "chunk_docs = [\n",
    "    Document(\n",
    "        page_content=row[\"Content\"],\n",
    "        metadata={\"Chunk No\": row[\"Chunk No\"], **eval(row[\"Metadata\"])}\n",
    "    )\n",
    "    for _, row in chunks_df.iterrows()\n",
    "]\n",
    "chunk_db = FAISS.from_documents(chunk_docs, embeddings)\n",
    "chunk_retriever = chunk_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# -----------------------------\n",
    "# 4. í›„ì²˜ë¦¬ í•¨ìˆ˜\n",
    "# -----------------------------\n",
    "def clean_answer(text: str) -> str:\n",
    "    if isinstance(text, str) and text.strip().startswith(\"ë‹µë³€\"):\n",
    "        return text.split(\":\", 1)[-1].strip()\n",
    "    return str(text).strip()\n",
    "\n",
    "def clean_question(q: str) -> str:\n",
    "    if not isinstance(q, str):\n",
    "        return \"\"\n",
    "    q = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\1\", q)   # **í…ìŠ¤íŠ¸** â†’ í…ìŠ¤íŠ¸\n",
    "    q = re.sub(r\"\\*\\*\\s*\", \"\", q)            # ** í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸\n",
    "    q = re.sub(r\"^\\s*>\\s*\", \"\", q)           # > í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸\n",
    "    return q.strip()\n",
    "\n",
    "# -----------------------------\n",
    "# 5. ì¹´ë“œ ìŠ¤íƒ€ì¼ FAQ í…œí”Œë¦¿\n",
    "# -----------------------------\n",
    "def format_faq_card(q, a, h1=\"\", h2=\"\", source=\"\"):\n",
    "    return f\"\"\"\n",
    "    <div style=\"margin:15px 10px; border:1px solid #ddd; border-radius:10px; overflow:hidden;\">\n",
    "      <details>\n",
    "        <summary style=\"padding:12px; background:#f5f5f5; cursor:pointer; display:flex; align-items:center;\">\n",
    "          <div style=\"background:#1976d2; color:white; font-weight:bold;\n",
    "                      border-radius:50%; width:32px; height:32px;\n",
    "                      display:flex; align-items:center; justify-content:center;\n",
    "                      margin-right:10px; font-size:16px; line-height:32px;\">Q</div>\n",
    "          <span style=\"font-weight:bold; font-size:16px;\">{q}</span>\n",
    "        </summary>\n",
    "        <div style=\"padding:15px; background:white; font-size:15px; line-height:1.6;\">\n",
    "          {a}\n",
    "          <br><br><span style=\"color:#666; font-size:13px;\">ì¶œì²˜: {h1} > {h2} ({source})</span>\n",
    "        </div>\n",
    "      </details>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. FAQ ê²€ìƒ‰\n",
    "# -----------------------------\n",
    "def search_faq(user_query):\n",
    "    results = faq_retriever.get_relevant_documents(user_query)\n",
    "    outputs = []\n",
    "    for r in results:\n",
    "        q = clean_question(r.page_content)\n",
    "        a = clean_answer(r.metadata.get(\"Answer\", \"\"))\n",
    "        h1 = r.metadata.get(\"Header 1\", \"\")\n",
    "        h2 = r.metadata.get(\"Header 2\", \"\")\n",
    "        source = r.metadata.get(\"Source\", \"\")\n",
    "        outputs.append(format_faq_card(q, a, h1, h2, source))\n",
    "    return \"\".join(outputs)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. FAQ ì „ì²´ ë³´ê¸°\n",
    "# -----------------------------\n",
    "def show_faq():\n",
    "    grouped = df_faq.groupby(\"Header 1\")\n",
    "    html_blocks = []\n",
    "    for h1, group in grouped:\n",
    "        html_blocks.append(f\"<h2 style='color:#1976d2; margin-top:40px;'>ğŸ“˜ {h1}</h2>\")\n",
    "        sub_group = group.groupby(\"Header 2\")\n",
    "        for h2, rows in sub_group:\n",
    "            if h2 and h2 != \"nan\":\n",
    "                html_blocks.append(f\"<h3 style='color:#444; margin-top:20px;'>ğŸ“Œ {h2}</h3>\")\n",
    "            for _, row in rows.iterrows():\n",
    "                q = clean_question(row[\"Question\"])\n",
    "                a = clean_answer(row[\"Answer\"])\n",
    "                source = row.get(\"Source\", \"\")\n",
    "                html_blocks.append(format_faq_card(q, a, h1, h2, source))\n",
    "    return \"\".join(html_blocks)\n",
    "\n",
    "# -----------------------------\n",
    "# 8. ì¼ë°˜ ê²€ìƒ‰ (Chunk ê¸°ë°˜, LLM ë‹¤ë“¬ê¸°)\n",
    "# -----------------------------\n",
    "def chunk_answer(query, retrieved_docs):\n",
    "    docs_text = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"[Chunk {doc.metadata.get('Chunk No')}] \"\n",
    "            f\"(Header1: {doc.metadata.get('Header 1','')}, \"\n",
    "            f\"Header2: {doc.metadata.get('Header 2','')}, \"\n",
    "            f\"Header3: {doc.metadata.get('Header 3','')})\\n\"\n",
    "            f\"{doc.page_content}\"\n",
    "            for doc in retrieved_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    ë„ˆëŠ” ì—°êµ¬ ë³´ê³ ì„œë¥¼ ìš”ì•½í•˜ëŠ” LLM ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤. \n",
    "    ì•„ë˜ ë¬¸ì„œ ì¡°ê°ë“¤ë§Œ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì‘ì„±í•˜ë¼. \n",
    "\n",
    "    [ìš”êµ¬ì‚¬í•­]\n",
    "    - ë¬¸ì„œ ë‚´ìš©ë§Œ í™œìš©í•  ê²ƒ (ìƒˆë¡œìš´ ì‚¬ì‹¤ ìƒì„± ê¸ˆì§€).\n",
    "    - ë‹µë³€ì€ 3~4ë¬¸ë‹¨, 600~800ì ë‚´ì™¸ë¡œ ì •ë¦¬.\n",
    "    - ê²°ë¡  ë¬¸ë‹¨ì€ ë°˜ë“œì‹œ 'ë”°ë¼ì„œ, ~ì´ë‹¤.' ë˜ëŠ” 'ê²°ë¡ ì ìœ¼ë¡œ, ~ë¼ê³  í•  ìˆ˜ ìˆë‹¤.' í˜•íƒœë¡œ ë§ˆë¬´ë¦¬.\n",
    "    - ë‹µë³€ í›„ ë°˜ë“œì‹œ \"ì¶œì²˜\" ì„¹ì…˜ì„ ì¶”ê°€í•˜ì—¬ ì‚¬ìš©í•œ Header1/2/3ì™€ Chunk Noë¥¼ ë‚˜ì—´í•  ê²ƒ.\n",
    "    - ì¶œë ¥ì€ ë°˜ë“œì‹œ HTML ì¹´ë“œ í˜•íƒœë¡œ (FAQ ì¹´ë“œ ìŠ¤íƒ€ì¼) ë°˜í™˜.\n",
    "\n",
    "    ì§ˆë¬¸: {query}\n",
    "\n",
    "    ë¬¸ì„œ ì¡°ê°:\n",
    "    {docs_text}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\"max_output_tokens\": 9000, \"temperature\": 0.5}\n",
    "        )\n",
    "\n",
    "        if response.candidates and response.candidates[0].content.parts:\n",
    "            answer = \"\".join(\n",
    "                [p.text for p in response.candidates[0].content.parts if hasattr(p, \"text\")]\n",
    "            ).strip()\n",
    "        else:\n",
    "            answer = \"[âš ï¸ ë‹µë³€ ì—†ìŒ: ëª¨ë¸ì´ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ì•ŠìŒ]\"\n",
    "\n",
    "    except Exception as e:\n",
    "        answer = f\"[âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}]\" \n",
    "        \n",
    "    # âœ… í›„ì²˜ë¦¬: ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±°\n",
    "    answer = answer.replace(\"```html\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "    # âœ… ì¤„ë°”ê¿ˆì„ HTML <br>ë¡œ ì¹˜í™˜ (f-string ë°–ì—ì„œ)\n",
    "    answer_html = answer.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "    # ğŸ“Œ ì¹´ë“œ UI ìŠ¤íƒ€ì¼ ê°ì‹¸ê¸°\n",
    "    return (\n",
    "        \"<div style='margin:15px 10px; border:1px solid #ddd; border-radius:10px; overflow:hidden;'>\"\n",
    "        \"<div style='padding:12px; background:#f5f5f5; font-weight:bold; font-size:16px;'>ğŸ“‘ ë¬¸ì„œ ê¸°ë°˜ ì‘ë‹µ</div>\"\n",
    "        f\"<div style='padding:15px; background:white; font-size:15px; line-height:1.6;'>{answer_html}</div>\"\n",
    "        \"</div>\"\n",
    "    )\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Hybrid Search í•¨ìˆ˜ ì •ì˜ (UIë³´ë‹¤ ìœ„ì— ìˆì–´ì•¼ í•¨)\n",
    "# -----------------------------\n",
    "FAQ_THRESHOLD = 0.7  # ì‹ ë¢°ë„ ê¸°ì¤€ê°’\n",
    "\n",
    "def hybrid_search(query, faq_retriever, chunk_retriever):\n",
    "    # FAQ ê²€ìƒ‰\n",
    "    faq_results = []\n",
    "    try:\n",
    "        faq_results = faq_retriever.vectorstore.similarity_search_with_score(query, k=3)\n",
    "    except Exception:\n",
    "        faq_results = [(doc, 1.0) for doc in faq_retriever.get_relevant_documents(query)[:3]]\n",
    "\n",
    "    faq_outputs = []\n",
    "    for doc, score in faq_results:\n",
    "        if score >= FAQ_THRESHOLD:\n",
    "            faq_outputs.append(format_faq_answer(doc))\n",
    "\n",
    "    # Chunk ê²€ìƒ‰ (í•­ìƒ ë©”ì¸)\n",
    "    chunk_results = chunk_retriever.get_relevant_documents(query)\n",
    "    chunk_output = chunk_answer(query, chunk_results) if chunk_results else \"âš ï¸ Chunk ê¸°ë°˜ ê²°ê³¼ ì—†ìŒ\"\n",
    "\n",
    "\n",
    "    # í•©ì¹˜ê¸°\n",
    "    if faq_outputs:\n",
    "        faq_block = \"\\n\\n\".join(faq_outputs)\n",
    "        return f\"{chunk_output}\\n\\n---\\n\\n{faq_block}\"\n",
    "    else:\n",
    "        return chunk_output\n",
    "    \n",
    "# âœ… ì§€ì—­ ê²€ìƒ‰ê¸° í•¨ìˆ˜ ìƒì„±ê¸°\n",
    "def local_search_factory(rows):\n",
    "    def local_search(query):\n",
    "        docs = [\n",
    "            Document(page_content=row[\"Content\"], metadata=eval(row[\"Metadata\"]))\n",
    "            for _, row in rows.iterrows()\n",
    "        ]\n",
    "        local_db = FAISS.from_documents(docs, embeddings)\n",
    "        retriever = local_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "        results = retriever.get_relevant_documents(query)\n",
    "        return chunk_answer(query, results)\n",
    "    return local_search\n",
    "# -----------------------------\n",
    "# 9. Gradio UI \n",
    "# -----------------------------\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ğŸ“˜ Tech Library ê²€ìƒ‰ ë·°ì–´\")\n",
    "\n",
    "    with gr.Tab(\"ì¼ë°˜ ê²€ìƒ‰ (ë¬¸ì„œ ê¸°ë°˜)\"):\n",
    "        gr.Markdown(\"### ğŸ” ì „ì²´ ë¬¸ì„œ ê²€ìƒ‰\")\n",
    "        global_query = gr.Textbox(label=\"ì „ì²´ ë¬¸ì„œì—ì„œ ì§ˆë¬¸í•˜ê¸°\")\n",
    "        global_output = gr.HTML()\n",
    "        global_query.submit(lambda q: hybrid_search(q, faq_retriever, chunk_retriever),\n",
    "                            global_query, global_output)\n",
    "\n",
    "        gr.Markdown(\"### ğŸ“˜ ëª©ì°¨ë³„ ê²€ìƒ‰\")\n",
    "        grouped = chunks_df.groupby(\"Metadata\")\n",
    "        \n",
    "        for idx, (meta, rows) in enumerate(grouped):\n",
    "            header1 = eval(meta).get(\"Header 1\", \"Unknown\")\n",
    "            header2 = eval(meta).get(\"Header 2\", \"\")\n",
    "            \n",
    "            with gr.Accordion(f\"{header1} > {header2}\", open=False):\n",
    "                local_query = gr.Textbox(label=f\"{header1} - {header2} ë‚´ ê²€ìƒ‰\")\n",
    "                local_output = gr.HTML()\n",
    "                search_fn = local_search_factory(rows)   # âœ… rowsë¥¼ í´ë¡œì €ë¡œ ìº¡ì²˜\n",
    "                local_query.submit(search_fn, local_query, local_output)\n",
    "\n",
    "\n",
    "    with gr.Tab(\"FAQ ê²€ìƒ‰\"):\n",
    "        query = gr.Textbox(label=\"FAQ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "        output = gr.HTML()\n",
    "        query.submit(search_faq, query, output)\n",
    "\n",
    "    with gr.Tab(\"FAQ ì „ì²´ ë³´ê¸°\"):\n",
    "        faq_output = gr.HTML(show_faq())\n",
    "\n",
    "demo.launch() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf59b04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
